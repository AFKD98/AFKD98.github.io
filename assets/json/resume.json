{
  "basics": {
    "name": "Ahmad Faraz Khan",
    "label": "Ph.D. Candidate in Computer Science",
    "email": "ahmadfk@vt.edu",
    "url": "https://afkd98.github.io",
    "summary": "Ph.D. candidate specializing in Machine Learning Systems, with a robust focus on Federated Learning optimization. Demonstrates comprehensive expertise across programming languages and development tools, contributing significantly to both academic research and practical applications.",
    "location": {
      "city": "Blacksburg",
      "region": "VA",
      "countryCode": "US"
    },
    "profiles": [
      {
        "network": "LinkedIn",
        "username": "ahmadfarazkhandurrani",
        "url": "https://www.linkedin.com/in/ahmadfarazkhandurrani/"
      }
    ]
  },
  "education": [
    {
      "institution": "Virginia Tech",
      "area": "Computer Science",
      "studyType": "Ph.D.",
      "startDate": "2020-12",
      "endDate": "Present",
      "gpa": "3.8",
      "courses": ["Machine Learning Systems", "Distributed Systems", "Deep Learning", "Machine Learning", "Cloud Development", "Computer Systems"]
    },
    {
      "institution": "LUMS",
      "area": "Computer Science",
      "studyType": "B.S.",
      "startDate": "2016-01",
      "endDate": "2020-01",
      "courses": ["Distributed Systems", "Deep Learning", "Machine Learning", "Cloud Development", "Computer Systems"]
    }
  ],
  "work": [
    {
      "name": "Virginia Tech, DSSL",
      "position": "Graduate Research Assistant",
      "startDate": "2020-12",
      "endDate": "Present",
      "summary": "Mentored by Dr. Ali Butt, focused on developing solutions for resource-constrained learning. My research spans the design of distributed systems, enhanced learning schedulers, and the fine-tuning of Large Language Models (LLMs), aiming at optimizing resource utilization, accuracy, and efficiency in privacy-aware learning environments.",
      "highlights": [
        "Built a distributed learning system in Pytorch for resource-constrained privacy-aware learning, enhancing resource utilization by 81x, scalability by 78x, and accuracy by 53%.",
        "Designed a distributed learning parameter server on Hadoop Spark to support over one million learning nodes, increasing scalability by 4x, reducing latency by 8x, and cutting costs by 2x.",
        "Developed a scheduler for distributed learning systems in Pytorch, which improved accuracy by 57% and reduced training time by 40%.",
        "Engineered an efficient, infinitely scalable, and cost-effective cache on AWS Lambda, ElastiCache, SageMaker, and EC2 for non-training workloads, decreasing latency by 99.9% and costs by 99.6%.",
        "Improved distributed ML schedulers in Pytorch to identify and eliminate adversarial data sources, increasing accuracy by 7% by successfully mitigating 100% of malicious data sources.",
        "Developed clustering-based personalized learning solutions in Pytorch for distributed ML systems, enhancing personalized accuracy by up to 45%.",
        "Designed a RAG-based context-aware LLM framework using Hugging Face and Pytorch, automating the adaptive online configuration of distributed cloud services to enhance resource efficiency.",
        "Implemented a Direct Preference Optimization (DPO)-based approach to mitigate sycophancy by fine-tuning LLMs on our curated dataset, reducing sycophancy by 64% in persona-based tests and 44% in preference-driven tests.",
        "Developed a DPO-based approach for prompt optimization without separate reward modeling for LLMs, improving score by 27% compared to supervised fine-tuning."
      ]
    },
    {
      "name": "i2c Inc.",
      "position": "Associate Data Engineer",
      "startDate": "2020-05",
      "endDate": "2020-12",
      "summary": "Spearheaded the development and maintenance of distributed databases, focusing on performance optimization and scalability."
    }
  ],
  "publications": [
    {
      "name": "Exposing the Gaps in the Large Language Models’ Ability to Understand Code",
      "publisher": "Submitted: ICSE'26",
      "releaseDate": "2025-3-16",
      "summary": "Developed the first benchmark for evaluating the robustness of LLMs for debugging in the presence of non-functional mutations in code, providing guidelines to engineers on how to improve automated debugging performance with LLMs."
    },
    {
      "name": "LADs: Leveraging LLMs for AI-Driven DevOps",
      "publisher": "Submitted: ACL'25",
      "releaseDate": "2025-2-15",
      "summary": "Developed a first-of-its-kind reasoning-based Agentic AI-driven DevOps platform for adaptive online configuration of cloud systems, employing context-aware prompting for optimal resource efficiency and reduced human effort and cost."
    },
    {
      "name": "IP-FL: Incentive-driven Personalization in Federated Learning",
      "publisher": "Published: IPDPS'25",
      "releaseDate": "2025-3-6",
      "summary": "Designed an incentive-driven personalized training and fine-tuning distributed learning framework for resource-constrained data-heterogeneous Edge devices. Enhanced personalized accuracy by up to 45%."
    },
    {
      "name": "FLStore: A Cache for Non-Training Workloads in Federated Learning",
      "publisher": "Published: MLSys'25",
      "releaseDate": "2025-7-31",
      "summary": "Designed 'FLStore' locality-aware processing cache for handling non-training workloads of distributed privacy-aware learning efficiently at low cost. Decreased latency up to 99.9% and cost up to 99.6%"
    },
    {
      "name": "DynamicFL: Federated Learning with Dynamic Communication Resource Allocation",
      "publisher": "Published: IEEE BigData'24",
      "releaseDate": "2024-12-15",
      "summary": "Designed 'DynamicFL' that dynamically allocates communication resources in distributed learning based on data heterogeneity, enhancing model accuracy by up to 10% compared to standard methods."
    },
    {
      "name": "Personalized Federated Learning Techniques: Empirical Analysis",
      "publisher": "Published: IEEE BigData'24",
      "releaseDate": "2024-12-15",
      "summary": "Conducted a thorough analysis of personalized ML algorithms, highlighting the trade-offs between privacy and performance."
    },
    {
      "name": "Mitigating Sycophancy in Large Language Models via Direct Preference Optimization",
      "publisher": "Published: IEEE BigData'24",
      "releaseDate": "2024-12-15",
      "summary": "Introduced a Direct Preference Optimization approach to mitigate sycophancy by fine-tuning LLMs on a curated dataset. Reduced sycophancy by 64% in persona-based tests and 44% in preference-driven tests."
    },
    {
      "name": "ICL: An Incentivized Collaborative Learning Framework",
      "publisher": "Published: IEEE BigData'24",
      "releaseDate": "2024-12-15",
      "summary": "Proposed a framework to incentivize collaboration in distributed learning environments."
    },
    {
      "name": "FLOAT: Federataed Learning Optimizations with Automated Tuning",
      "publisher": "Published: ACM EuroSys'24",
      "releaseDate": "2024-4-22",
      "summary": "Designed 'FLOAT', a framework for enabling distributed learning and fine-tuning with high efficiency and resource utilization at low cost on constrained and heterogeneous Edge devices, leveraging Reinforcement Learning with Human Feedback. Improved resource utilization by 81x, scalability by 78x, and accuracy by 53%."
    },
    {
      "name": "Prompt optimization for LLMs",
      "publisher": "Submitted: COLM'24",
      "releaseDate": "2024-7-9",
      "summary": "Developed a Direct Preference Optimization approach harnessing human preferences for prompt optimization of text-to-image tasks. Improved score by 27% compared to supervised fine-tuning"
    },
    {
      "name": "Towards cost-effective and resource-aware aggregation at Edge for Federated Learning",
      "publisher": "Published: IEEE BigData'23",
      "releaseDate": "2023-12-15",
      "summary": "Developed an adaptive aggregator that significantly enhances scalability and time efficiency for Federated Learning on Edge and IoT devices. Increased scalability by 4x, reducing latency by 8x, and cutting costs by 2x"
    },
    {
      "name": "A survey on attacks and their countermeasures in deep learning: Applications in deep neural networks, federated, transfer, and deep reinforcement learning",
      "publisher": "Published: IEEE Access'24",
      "releaseDate": "2023-10-20",
      "summary": "Conducted a survey on adversarial tactics in deep learning models, emphasizing their applications and distinct features."
    },
    {
      "name": "Distributed Learning Schedulers",
      "publisher": "Published: FL-AAAI’22, IEEE CLOUD’22, AAAI-AIES’24",
      "releaseDate": "2022-7-10",
      "summary": "Developed a scheduler for distributed learning systems in Pytorch, which improved accuracy by 57% and reduced training time by 40%."
    },
    {
      "name": "Heterogeneity-Aware Adaptive Federated Learning Scheduling",
      "releaseDate": "2022-12",
      "publisher": "Published: IEEE BigData'22",
      "summary": "Proposes an adaptive scheduling method for federated learning that addresses resource and data heterogeneity, aiming to improve training efficiency and fairness."
    },
    {
      "name": "TIFF: Tokenized Incentive for Federated Learning",
      "publisher": "Published: IEEE BigData'22",
      "releaseDate": "2022-07",
      "summary": "Introduces a token-based incentive mechanism to encourage high-quality data contribution and sustained participation in federated learning systems."
    },
    {
      "name": "Tokenized Incentive for Federated Learning",
      "releaseDate": "2022-07",
      "publisher": "Published: AAAI'22",
      "summary": "Presents a tokenized incentive framework designed to motivate clients' participation and data sharing in federated learning environments."
    },
    {
      "name": "Privacy Preserving and Feature Importance Based Incentive Mechanism in Vertical Federated Learning",
      "publisher": "Submitted: ICML'25",
      "releaseDate": "2022-7-9",
      "summary": "Monetized VFL with PERFACY-FL, an incentive mechanism valuing data quality and privacy using Homomorphic Encryption, boosting participation and profitability."
    },
    {
      "name": "PETER: Privacy-Preserving Vertical Federated Learning Against Feature Inference Attacks",
      "publisher": "Submitted: TIFS'24",
      "releaseDate": "2025-6-12",
      "summary": "Proposed a lossless and efficient defense mechanism for inference attacks in Vertical Federated Learning environments."
    }
  ],
  "skills": [
    {
      "name": "Programming Languages",
      "level": "Expert",
      "keywords": ["Python", "Javascript", "C/C++", "Java", "Go"]
    },
    {
      "name": "Tools & Libraries",
      "level": "Expert",
      "keywords": [
        "LangChain",
        "Ray",
        "Spark MLlib",
        "Hugging Face",
        "Ollama",
        "PyTorch",
        "TensorFlow",
        "PySpark",
        "AWS Suite",
        "Pandas",
        "Numba",
        "Dask",
        "Docker",
        "IBMfl lib",
        "FLOWER",
        "FedScale",
        "Hadoop",
        "Kubernetes",
        "OpenFaaS",
        "CUDA"
      ]
    }
  ],
  "languages": [
    {
      "language": "English",
      "fluency": "Fluent"
    }
  ],
  "interests": [
    {
      "name": "Federated Learning",
      "keywords": ["Resource Optimization", "Model Performance", "System and Data Heterogeneity"]
    },
    {
      "name": "Machine Learning Systems",
      "keywords": ["Scalability", "Efficiency", "Cloud Development"]
    }
  ],
  "projects": [
    {
      "name": "ML System Optimization",
      "summary": "Developed algorithms to enhance ML system architectures for improved resource allocation, scalability, and efficiency.",
      "highlights": [
        "Designed and implemented DynamicFL to address heterogeneity in federated learning, published in IEEE BigData'24 (Best Paper).",
        "Created algorithms for personalized federated learning techniques, leading to empirical insights published in IEEE BigData'24.",
        "Optimized distributed ML systems for resource-constrained environments, contributing to impactful publications in EuroSys'24 and IEEE BigData'23."
      ],
      "startDate": "2020-12",
      "endDate": "Present"
    },
    {
      "name": "Federated Learning Frameworks",
      "summary": "Led the design and development of both Horizontal and Vertical Federated Learning frameworks, integrating MLOps pipelines with AWS cloud resources.",
      "highlights": [
        "Developed HFL & VFL frameworks with tokenized incentives for participation, resulting in publications in AAAI and IEEE CLOUD.",
        "Integrated MLOps pipelines with AWS resources to ensure scalability and reliability.",
        "Contributed to the development of incentive mechanisms for collaborative learning frameworks, as published in IEEE BigData'24 and IPDPS'25."
      ],
      "startDate": "2020-12",
      "endDate": "Present"
    },
    {
      "name": "LLM Fine-Tuning and Optimization",
      "summary": "Developed methods for fine-tuning large language models (LLMs) to reduce sycophancy, enhance privacy, and optimize prompts for specific tasks.",
      "highlights": [
        "Mitigated sycophancy in LLMs using Direct Preference Optimization, published in IEEE BigData'24.",
        "Fine-tuned LLMs with privacy-aware data for use in federated learning systems.",
        "Designed prompt optimization techniques tailored for text-to-image synthesis, currently under review at COLM'24."
      ],
      "startDate": "2021-01",
      "endDate": "Present"
    },
    {
      "name": "Privacy-Preserving Machine Learning",
      "summary": "Developed privacy-preserving mechanisms for federated learning to counter feature inference attacks and enhance security.",
      "highlights": [
        "Designed PETER: a privacy-preserving framework for vertical federated learning, under review at TIFS'24.",
        "Proposed feature importance-based incentive mechanisms for federated learning, to be submitted to AAAI'25.",
        "Surveyed security threats in deep learning and proposed countermeasures, published in IEEE Access."
      ],
      "startDate": "2021-06",
      "endDate": "Present"
    }
  ]
}
